{
 "metadata": {
  "name": "objective_performance"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Objective Performance Tests\n",
      "## Here we are going to test what is to be gained from compiling our code in three different parts of the geoCPM workflow. \n",
      "## The speed of these functions is crucial since they are run thousands of times per simulation step.\n",
      "\n",
      "### First we need to get the data ready."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numba.decorators import jit, autojit\n",
      "from numba import float64, float32, i4, i1\n",
      "import pandas as pd\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import itertools\n",
      "import time \n",
      "import random\n",
      "from PIL import Image, ImageDraw\n",
      "import networkx as nx\n",
      "import multiprocessing as mp\n",
      "import cProfile as profile\n",
      "import pstats, io\n",
      "import scipy.sparse\n",
      "import math\n",
      "\n",
      "import fcomparator\n",
      "import sys\n",
      "sys.path.insert(0,'..')\n",
      "import shapefile #This is a modified version. Patches will be submitted upstream.\n",
      "print \"Shapefile: '%s'.\" % shapefile.__file__\n",
      "import geocpm_core as gcpm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Shapefile: '../shapefile.pyc'.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sf = shapefile.Reader(\"../static/data/indiana/Census_Historical_MCD_IN\", quiet=True)\n",
      "df = sf.shapeRecordDataFrame()\n",
      "print \"Loaded %i records.\" % len(df.index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loaded 1011 records.\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_frame = gcpm.load_shapefile(\"../static/data/indiana/Census_Historical_MCD_IN\")\n",
      "neighbor_graph = gcpm.make_graph(data_frame)\n",
      "## Number of groups\n",
      "K = 9\n",
      "## Random initial seed\n",
      "for n in neighbor_graph:\n",
      "    neighbor_graph.node[n]['group'] = random.randint(0,K-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Drawing took 0.401 seconds.\n",
        "Getting neighbor weights took 0.014 seconds."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Making neighbor graph took 0.185 seconds."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1.  Compactness. We want electoral borders that are relatively compact, not all long and wiggly. We can try to do this by minimizing the surface area of the electoral regions.\n",
      "\n",
      "### We start with a sami-naive and mostly idiomatic algorithm, and then try out some variants."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#@autojit\n",
      "def compactness(G, K, idx_list=None):\n",
      "    contact_list = np.zeros(K, dtype=np.uint32)\n",
      "    if idx_list == None:\n",
      "        idx_list = G.nodes_iter()\n",
      "    for idx in idx_list:\n",
      "        my_group = G.node[idx]['group']\n",
      "        for nbr in G[idx]:\n",
      "            if nbr < idx and G.node[nbr]['group'] != my_group:\n",
      "                contact_list[my_group] += G[idx][nbr]['weight']\n",
      "    return contact_list.sum()\n",
      "\n",
      "def vector_compactness(groups, adj):\n",
      "    J = 0\n",
      "    for r in xrange(adj.shape[0]):\n",
      "        my_group = groups[r]\n",
      "        #print (adj[r] != groups[r])[0]\n",
      "        others = [adj[r,:r] != my_group]\n",
      "        J += adj[r][others].sum()\n",
      "    return J\n",
      "\n",
      "def compactness_II(G, groups, adj=None):\n",
      "    J = 0\n",
      "    for n,nbrsdict in G.adjacency_iter():\n",
      "        my_group = groups[n]\n",
      "        for nbr, eattr in nbrsdict.items():\n",
      "            if nbr < n and my_group != groups[nbr]:\n",
      "                J += eattr['weight']\n",
      "    return J\n",
      "\n",
      "#@autojit\n",
      "def jit_compactness(G, groups, adj):\n",
      "    J = 0\n",
      "    for tup in G.edges_iter(data=True):\n",
      "        if groups[tup[0]] != groups[tup[1]]:\n",
      "            J += tup[2]['weight']\n",
      "    return J\n",
      "    \n",
      "def sparse_compactness(G, groups, adj):\n",
      "    J = 0\n",
      "    for r in xrange(adj.shape[0]):\n",
      "        my_group = groups[r]\n",
      "        #print (adj[r] != groups[r])[0]\n",
      "        rv = adj.getrowview(r)\n",
      "        others = filter(lambda x: x < r and groups[x] != my_group, rv.rows[0])\n",
      "        #print others\n",
      "        \n",
      "#@autojit\n",
      "def jit_vector_compactness_II(groups, adj):\n",
      "    J = 0\n",
      "    for r in xrange(adj.shape[0]):\n",
      "        #my_group = groups[r]\n",
      "        #for c in xrange(r):\n",
      "        for c in np.nonzero(adj[r,:r])[0]:\n",
      "            if adj[r,c] and groups[c] != groups[r]:\n",
      "                J += adj[r,c]\n",
      "    return J\n",
      "\n",
      "@jit(argtypes=[i1[:], i4[:,:]], restype=i4)\n",
      "def jit_vector_compactness(groups, weights):\n",
      "    J = np.zeros(weights.shape[0], dtype=np.uint32)\n",
      "    for r in xrange(weights.shape[0]):\n",
      "        #print groups[weights[r,0]], groups[weights[r,1]]\n",
      "        if groups[weights[r,0]] != groups[weights[r,1]]:\n",
      "            J[r] = weights[r,2]\n",
      "    return J.sum()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### We'll use the FComparator to compare runtimes of the different functions. Note that not all of them actually work."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "groups = np.array([neighbor_graph.node[idx]['group'] for idx in xrange(len(df))], dtype=np.int8)\n",
      "adj = np.array(nx.to_numpy_matrix(neighbor_graph, weight='weight'), dtype=np.int32)\n",
      "weights = np.array([(u,v,w['weight']) for (u,v,w) in neighbor_graph.edges(data=True)], dtype=np.uint32)\n",
      "sp_adj = scipy.sparse.lil_matrix(adj)\n",
      "\n",
      "fc = fcomparator.FComparator()\n",
      "fc.add(compactness, (neighbor_graph, K))\n",
      "fc.add(vector_compactness, (groups, adj))\n",
      "fc.add(compactness_II, (neighbor_graph,groups,adj))\n",
      "fc.add(jit_compactness, (neighbor_graph,groups,adj))\n",
      "fc.add(sparse_compactness, (neighbor_graph, groups,sp_adj))\n",
      "fc.add(jit_vector_compactness_II, (groups, adj))\n",
      "fc.add(jit_vector_compactness, (groups, weights))\n",
      "fc.run(5)\n",
      "print\n",
      "fc.compare(jit_vector_compactness, compactness)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Data after 5 runs:\n",
        "Name                            Result        (    min/   mean/    max)\n",
        "------------------------------------------------------------------------\n",
        "compactness                     132144        (0.00612/0.00632/0.00678)\n",
        "vector_compactness              148432        (0.02825/0.02834/0.02852)\n",
        "compactness_II                  132144        (0.00571/0.00577/0.00584)\n",
        "jit_compactness                 132144        (0.00764/0.00768/0.00771)\n",
        "sparse_compactness              None          (0.05251/0.05262/0.05269)\n",
        "jit_vector_compactness_II       132144        (0.01789/0.01792/0.01797)\n",
        "jit_vector_compactness          132144        (0.00006/0.00007/0.00008)\n",
        "\n",
        "On average, jit_vector_compactness is 88 times faster than compactness.\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###... and the results speak for themselves.\n",
      "\n",
      "## 2.  Population Equality: We want the electoral districts to have roughly the same number of people in each. We can achieve this by minimizing the variance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#@autojit\n",
      "#@jit(argtypes=[_object, i4, _object], restype=float64)\n",
      "def population_equality(G, K, pops):\n",
      "    population_vector = np.zeros(K, dtype=np.uint64)\n",
      "    for idx in df.index:\n",
      "        population_vector[G.node[idx]['group']] += pops[idx]\n",
      "    return population_vector.std()\n",
      "\n",
      "def vector_population_equality(groups, K, pops):\n",
      "    population_vector = np.zeros(K, dtype=np.int32)\n",
      "    for i in range(K):\n",
      "        population_vector[i] = pops[groups == i].sum()\n",
      "    return population_vector.std()\n",
      "\n",
      "@jit(argtypes=[i1[:], i1, i4[:]], restype=float64)\n",
      "def jit_population_equality(groups, K, pops):\n",
      "    population_vector = np.zeros(K, dtype=np.int32)\n",
      "    for i in xrange(len(groups)):\n",
      "        population_vector[groups[i]] += pops[i]\n",
      "    return population_vector.std()    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### We're just going to go ahead and prefetch the population data into a numpy array for fastest access."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pops = np.array(df['record', 'POP2000'], dtype=np.int32)\n",
      "\n",
      "fc = fcomparator.FComparator()\n",
      "fc.add(population_equality, (neighbor_graph, K, pops))\n",
      "fc.add(vector_population_equality, (groups, K, pops))\n",
      "fc.add(jit_population_equality, (groups, K, pops))\n",
      "\n",
      "fc.run(5)\n",
      "print\n",
      "fc.compare(jit_population_equality, population_equality)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Data after 5 runs:\n",
        "Name                            Result        (    min/   mean/    max)\n",
        "------------------------------------------------------------------------\n",
        "population_equality             110890.49891  (0.00738/0.00759/0.00821)\n",
        "vector_population_equality      110890.49891  (0.00029/0.00030/0.00032)\n",
        "jit_population_equality         110890.49891  (0.00007/0.00007/0.00007)\n",
        "\n",
        "On average, jit_population_equality is 107 times faster than population_equality.\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### ... and the results speak for themselves."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    }
   ],
   "metadata": {}
  }
 ]
}